## 머신러닝 프로젝트 처음부터 끝까지
### 2.2 큰 그림 보기
- 캘리포니아 인구 조사 데이터를 사용해 캘리포니아의 주택 가격 모델 만들기
### 2.2.1 문제 정의
- 지도 학습 : 레이블 된 훈련 샘플 존재
- 다중 회귀 : 예측에 사용할 특성이 여러 개
- 단변량 회귀 : 구역마다 하나의 값을 예측 (<-> 다변량 회귀)
### 2.2.2성능 측정 지표 선택
- 오차 = (함수를 통해 계산된 값) - (레이블 값)
- 평균 제곱근 오차 (RMSE) : 오차를 제곱하여 평균을 낸 뒤 루트
- 평균 절대 오차 (MAE) : 오차의 절대값의 평균
### 2.2.3 가정 검사
- 가격이 아닌 저렴/보통/고가 같은 카테고리를 출력값으로 원한다면 회귀가 아닌 분류 작업이 됨
### 2.3.6 데이터 구조 훑어보기
- Null 값이 존재하는지 확인 : head 메서드로 Non-Null 행 수를 확인 가능
- 숫자형이 아닌 타입 확인 : value_counts 메서드로 범주형인지 확인 가능
- 숫자형 특성의 요약 정보 확인 : describe 메서드로 count, mean(평균), std(표준편차), min, max, 백분위수 등을 확인 가능
- 히스토그램을 사용해 데이터 형태를 빠르게 검토 가능
### 2.3.7 테스트 세트 만들기
- 랜덤 샘플링
  - 프로그램 재시작 후에도 같은 샘플을 가져올 수 있어야 함
    - 저장 후 다시 불러오기 방식
    - 난수 발생기에 시드 값 부여
  - 데이터 셋 업데이트 후에도 안정적인 샘플링이 되어야 함
    - 샘플의 식별자를 사용해 테스트 세트로 보낼지 말지 결정 (ex. 해시값)
    - crc32 : cyclic redundancy check 순환 중복 검사, 일종의 해시 함수
    - 예제를 실행해 보면 정확하게 20%만 가져와지는 것은 아닌 걸 볼 수 있음
  - sklearn.model_selection의 tran_test_split 메서드를 이용해서 편하게 샘플링 가능
- 계층별 샘플링
  - 데이터 셋이 충분히 크다면 문제가 되지 않지만, 충분히 크지 못하다면 순수한 랜덤 방식으로는 샘플링 편향이 생길 수 있음
  - 미리 계층이라는 동질의 그룹으로 나눈 후 비율을 유지시키면서 샘플링을 진행하면 이러한 문제를 피할 수 있음
### 2.4.1 지리적 데이터 시각화하기
- 산점도
- alpha 옵션으로 간단하게 밀집도를 확인 가능
- s(크기), c(색상) 등을 이용하여 좀 더 유용한 산점도를 그릴 수 있음
- 이러한 산점도로 특성 간의 관계를 파악 가능
### 2.4.2 상관관계 조사하기
- 표준 상관계수(피어슨의 r)
- -1 ~ 1 사이의 값으로 높을 수록 상관관계가 강함
- 선형적인 상관관계만 측정하기 때문에 주의 필요
### 2.4.3 특성 조합으로 실험하기
- 예를 들면 특정 구역의 방 개수는 유용하지 않을 수 있지만, 가구당 방 개수는 유용할 수 있음
- 이러한 조합된 특성으로 상관관계를 다시 조사하면 더 많은 인사이트를 얻을 수 있음
### 2.5.1 데이터 정제
- 특성에 값이 없는 경우
  - 값 제거
  - 전체 특성 삭제
  - 대체 (누락된 값을 어떤 값으로 채움)
### 2.5.2 텍스트와 범주형 특성 다루기
- 범주형 특성
  - 숫자로 치환 가능, 하지만 순서가 있는 카테고리의 경우는 상관이 없지만 서로 연관이 없는 카테고리는 더 가까운 숫자를 더 비슷하다고 생각하는 오류가 생김
  - 카테고리별 이진 특성, 원-핫 인코딩으로 해결 가능, 여러 특성으로 나눠 하나만 1로 설정하고 나머지는 0으로 설정하는 방식
  - 희소 행렬 : 0이 대부분인 행렬을 효율적으로 표현
  - 카테고리 수가 많다면 많은 수의 입력 특성을 만들기 때문에 성능 저하가 일어날 수 있음, 이러한 경우 ocean_proximity 특성을 해안까지의 거리로 바꾸는 등의 시도를 해볼 수 있음
### 2.5.3 특성 스케일 변환
- 머신러닝 알고리즘은 숫자 특성의 스케일이 많이 다르면 제대로 작동하지 않음
- min-max 스케일링 (정규화) : 각 특성에 대해서 0~1 범위에 들어가도록 스케일 조정
- 표준화 : 평균을 뺀 후 표준편차로 나눔 (평균 0, 표준편차 1), 이상치에 영향을 덜 받음
- 특성 분포의 꼬리가 두꺼울 때
  - 멱법칙의 분포 형태 (거듭제곱, ex. 인구 수) -> 로그값으로 변경, 버킷타이징 (ex. 백분위수)
  - 멀티모달 분포 (정점이 두 개 이상) -> 버킷타이징, 방사 기저 함수 (RBF, 입력값과 고정 포인트 사이의 거리에 의존)
  - 입력 특성뿐 아니라 타깃 값도 적용 가능, 역변환 메서드도 존재
### 2.5.5 변환 파이프라인
- 올바른 순서대로 실행 필요, pipe 메서드
### 2.6.1 훈련 세트에서 훈련하고 평가하기
- 선형회귀, 결정트리 모델 시도
- RMSE로 평가
- 훈련 세트로 평가 했을 때 과대적합되었을 가능성 확인 필요
### 2.6.2 교체 검증으로 평가
- k-폴드 교차 검증 : 10개의 서브셋으로 랜덤 분할하여 10번 훈련-평가, 매번 다른 폴드 선택 나머지 폴드는 평가에 사용
- 랜덤 포레스트 모델 시도, 다양한 모델을 시도해 보고 가능성 있는 2~5개의 모델을 선정
### 2.7 모델 미세 튜닝
- 모델을 추린 후 미세 튜닝
### 2.7.1 그리드 서치
- 하이퍼파라미터 조합을 찾을 때까지 수동으로 지정
- 배열로 입력하여 입력된 수치 중 최적의 값을 찾을 수 있음
### 2.7.2 랜덤 서치
- 랜덤 범위와 반복 횟수를 정하여 랜덤하게 하이퍼파라미터 값을 찾음
### 2.7.3 앙상블 방법
- 한 가지 모델만 사용하지 않고 여러 모델을 연결해 보는 방법
- ex. k-최근접 이웃 모델을 훈련하고 미세 튜닝한 후 랜덤 포레스트의 에측과 평균하여 사용
### 2.7.4 최상의 모델과 오차 분석
- 최상의 모델을 분석하여 좋은 인사이트를 얻는 경우가 많음
- 예시로 RandomForestRegressor의 중요도를 이용하여 덜 중요한 특성들을 제외할 수 있음
