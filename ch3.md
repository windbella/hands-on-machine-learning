##  분류
### 3.1 MNIST
- 70,000개의 손글씨 이미지 데이터 셋
- 데이터 프레임(테이블 형태)이 적합하지 않아 넘파이 배열로 데이터를 로드
### 3.2 이진 분류기 훈련
- 문제를 단순화하여 하나의 숫자만 식별 (ex. 5-감지기, 5 - 5 아님)
### 3.3 성능 측정
- 정확도(accuracy)
- 오차 행렬(confusion matrix) : 행 - 실제 클래스, 열 - 예측한 클래스
- 진짜 음성(true negative) : 음성을 음성으로 올바르게 판단
- 거짓 양성(false positive, 1종 오류) : 음성을 양성으로 잘못 판단
- 거짓 음성(false negative, 2종 오류) : 양성을 음성으로 잘못 판단
- 진짜 양성(true positive) : 양성을 양성으로 올바르게 판단
- 앞 - 판단이 맞았는지, 뒤 - 음성/양성으로 식별했는지
- 정밀도(precision) : TP / TP + FP, 양성으로 판단한 것 중 얼마나 많이 실제 양성인가, 양성 예측 정확도
- 재현율(recall) : TP / TP + FN, 실제 양성인 것 중 얼마나 많이 양성으로 판단했는가, 정확하게 감지한 양성 샘플의 비율, 민감도(sensitivity), 진짜 양성 비율(TPR, true positive rate)
- 정밀도와 재현율을 F라는 하나의 점수로 만들면 편리함, 조화평균을 주로 사용, 조화 평균은 재현율과 정밀도가 모두 높아야 함
- 조화평균 : 개별 데이터의 역수의 평균에 대한 역수
- 정밀도/재현율 트레이드오프 : 일반적으로 정밀도가 올라가면 재현율이 내려가고 그 반대도 마찬가지 지만, 둘 중 한 지표가 더 중요한 케이스가 있기 때문에 잘 판단해야 한다.
- 결정 함수, 결정 임곗값 : 임계 값 ↑ 정밀도 ↑ 재현율 ↓, 임계 값 ↓ 정밀도 ↓ 재현율 ↑
- ROC 곡선 : 거짓 양성 비율(FPR, 폴-아웃, 1 - TNR, 특이도)에 대한 진짜 양성 비율(TPR = 재현율) 곡선, 곡선 아래 면적(AUC)를 측정해 분류기 비교 가능, AUC가 높아야 우수
### 3.4 다중 분류
- 둘 이상의 클래스를 구별
- 일부 알고리즘은 여러 개의 클래스를 처리 가능하지만 일부는 그렇지 않음, 하지만 이진 분류기 여러 개를 사용해 다중 클래스 분류가 가능함
- OvR(one-versus-the-rest, OvA, one-versus-all) : 클래스 N개에 N개의 이진 분류기를 훈련하여 가장 점수가 높은 것을 클래스로 선택
- OvO(one-versus-one) : 각 클래스 끼리의 구별로 이진 분류기 훈련, N * (N - 1) / 2, 모든 분류를 모두 통과시켜서 가장 많이 양성으로 분류된 클래스를 선택
- OvO의 장점은 각 분류기의 훈련에 전체 훈련 세트 중 구별한 두 클래스에 해당하는 샘플만 있으면 된다는 점임
### 3.5 오류 분석
- 오차 행렬을 시각화하여 분류기가 어떤 오류를 범하는지 인사이트를 얻을 수 있음
### 3.6 다중 레이블 분류
- 샘플마다 여개의 레이블이 부여되어 있는 경우, 여러개의 이진 꼬리표
- 평가 시 각 레이블의 F1 점수를 구하고 평균을 점수로 채택, 지지도를 기반으로 가중치를 줄 수도 있음
- 지지도(support) : 타겟 레이블에 속한 샘플 수
### 3.7 다중 출력 분류
- 다중 레이블 분류의 꼬리표가 이진이 아닌 두 개 이상의 값을 가질 수 있는 분류
