### 심층 신경만 훈련

## 그레이디언트 소실과 폭주 문제
- 그레이디언트 소실
  - 하위 층으로 진행될수록 그레이디언트가 점점 작아지는 현상
- 그레이디언트 폭주
  - 하위 층으로 진행될수록 그레이디언트가 점점 커져서 발산하는 현상
- 원인
  - 시그모이드 활성 함수를 사용하고 평균이 0이고 표준 편차가 1인 정규 분포로 초기화했을 때 출력의 분산이 입력의 분산보다 큼
  - 신경망의 위쪽으로 갈수록 층을 지날 때마다 분산이 계속 커져 높은 층에서는 활성화 함수가 0이나 1로 수렴
  - 입력이 커지면 0이나 1로 수렴하고 기울기가 0에 가까워져 역전파가 될 때 사실상 하위 신경망으로 전달할 그레이디언트가 거의 없고 아래쪽 층에는 아무것도 도달하지 않게 됨   
![함수의 수렴](https://velog.velcdn.com/images/kyungmin1029/post/def9ea6a-4ba6-4b14-9850-2e6e9c166355/image.png)

## 해결 방법
- 이론
  - 예측 시 정방향, 역전파 시 역방향, 양방향 신호가 적절히 흘러야 함
  - 각 층의 출력에 대한 분산이 입력에 대한 분산과 같아야 함
  - 역방향에서 층을 통과하기 전과 후의 그레이디언트 분산이 동일해야 함
- 초기화
  - 각 층의 연결 가중치를 적절히 초기화 하면 문제를 줄일 수 있음
  - 글럿 초기화 (시그모이드 활성 함수를 사용할 때)   
![글럿 초기화](https://velog.velcdn.com/images/kyungmin1029/post/3a137164-be17-4271-81b0-bfc9f31e8a95/image.png)
  - 활성화 함수별 초기화 전략   
![초기화 전략](https://velog.velcdn.com/images/kyungmin1029/post/9d13fc2e-b393-41b8-89ba-810942ba5e7c/image.png)
- 활성화 함수
  - 예전에는 생물학적 뉴런의 방식과 비슷한 시그모이드 활성 함수가 최선의 선택으로 생각됨
  - 다른 활성화 함수가 심층 신경망에서 훨씬 더 잘 작동한다는 사실이 밝혀짐 (특히 ReLU, Rectified Linear Unit)
  - ReLU 함수도 완벽하지 않고, 죽은 ReLU 등 여러 문제가 있기 때문에 개선이나 더 좋은 함수를 찾기 위한 여러 시도가 있음
  - 죽은 ReLU : 일부 뉴런이 훈련하는 동안 0이외의 값을 출력하지 않는 현상
- 배치 정규화
  - 초기화 및 활성화 함수 선택을 적절히 하면 훈련 초기 단계에 문제를 줄일 수 있지만 훈련이 진행되다 보면 다시 문제가 발생할 수 있음
  - 각 층에 배치 정규화 층을 둬서 문제를 해결할 수 있음
  ```
  model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=[28, 28]),
    tf.keras.layers.Dense(300, kernel_initializer="he_normal", use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Activation("relu"),
    tf.keras.layers.Dense(100, kernel_initializer="he_normal", use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Activation("relu"),
    tf.keras.layers.Dense(10, activation="softmax")
  ])
  ```
  - 배치 정규화는 규제와 같은 역할을 하여 다른 규제 기법의 필요성을 줄여줌
  - 그러나 배치 정규화는 모델의 복잡도를 키워 무겁고 느려짐
- 그레이디언트 클리핑
  - 역전파 될 때 특정 임곗값을 넘어서지 못하도록 그레이디언트를 잘라내는 것
  - 일반적으로 배치 정규화를 사용하기 까다로운 순환 신경망에서 사용
 
## 사전 훈련된 층 재사용하기
- 전이 학습
  - 해결하려는 문제와 유사한 유형의 문제를 처리한 신경망이 있는지 찾음
  - 최상위 층을 제외한 다른 층들을 재사용하여 훈련 속도를 크게 향상시킬 수 있음
  - 속도뿐 아니라 필요한 훈련 데이터도 크게 줄여줌
![재사용](https://velog.velcdn.com/images/kyungmin1029/post/1c75d11c-abe9-4ac6-9249-59b1723c04a7/image.png)
- 비지도 사전 훈련
  - 레이블 된 훈련 데이터는 적고, 레이블 되지 않은 훈련 데이터를 많이 모을 수 있는 상황이 흔히 발생함
  - 레이블 되지 않은 데이터 오토인코더나 GAN을 이용해 비지도 훈련을 실행
  - 비지도 훈련한 모델의 하위 층을 재사용하여 지도 학습을 실행해 최종 네트워크를 세밀하게 튜닝함
![비지도 사전 훈련](https://velog.velcdn.com/images/kyungmin1029/post/dff201c5-f432-4b06-98c7-f8d0e21987a2/image.png)
- 보조 작업에서 사전 훈련
  - 쉽게 얻을 수 있는 데이터를 활용한 보조 작업을 먼저 훈련하고, 훈련된 모델의 하위 층을 재사용해 실제 훈련을 진행
  - 예로 각 사람의 얼굴 사진을 수백 개씩 모으긴 어렵기 때문에 랜덤으로 많은 인물의 이미지를 수집해 두 개의 다른 이미지가 같은 사람 것인지 감지하는 신경망을 훈련
  - 얼굴의 특성을 잘 감지하도록 훈련된 이 모델을 이용해서 얼굴을 인식하는 실제 모델을 적은 양의 훈련 데이터로도 훈련이 가능
  - 자연어 처리에서도 많이 활용 됨 (랜덤한 말뭉치의 중간을 임의로 제거하고 누락된 단어를 예측하는 모델을 훈련 시키면 다른 작업에서도 유용하게 사용됨)
 
## 고속 옵티마이저
- 아주 큰 심층 신경망의 훈련 속도는 심각하게 느릴 수 있음
- 표준적인 경사 하강법 옵티마이저 대산 더 빠른 옵티마이저를 사용해 훈련 속도를 높일 수 있음
- 모멘텀 최적화
  - 경사가 완만할 때는 작은 스텝으로 가파를 때는 큰 스텝으로 이동 
- 네스테로프 가속 경사
  - 모멘텀 최적화으 변형으로 더 빠름
- AdaGrad
  - 가장 가파른 경사를 따라가다 보면 방향이 부정확해 돌아가는 경우가 많음
  - 가장 가파른 차원을 따라 그레이디언트 벡터의 스케일을 감소시켜 더 정확한 방향으로 찾아가게 함   
![AdaGrad](https://velog.velcdn.com/images/kyungmin1029/post/b787aa2d-fe58-45f7-9398-ae86e7cd4422/image.png)
- RMSProp
  - AdaGrad는 너무 빨리 느려져서 전역 최적점에 수렴하지 못하는 위험이 있음
  - 가장 최근 반복된 그레이디언트만 누적하여 이 문제를 해결함
- Adam
  - 적응적 모멘트 추정으로 모멘텀 최적화와 RMSProp를 합친 아이디어
- AdaMax
  - Adam의 변형
  - AdaMax가 실전에더 더 안정적, Adam의 성능이 더 좋음
  - Adam이 잘 동작하지 않을 때 시도할 수 있는 옵티마이저
- Nadam
  - Adam에 네스테로프 기법을 더한 아이디어
- AdamW
  - Adam에 가중치 감소라는 규제 기법을 추가한 버전 
- 학습률 스케줄링
  - 좋은 학습률을 찾는 것도 매우 중요   
![학습률](https://velog.velcdn.com/images/kyungmin1029/post/b4470f2f-6126-420d-9a81-802eb0ae6fc1/image.png)
  - 일정한 학습률보다 더 나은 방법으로 학습 스케줄이 있음
  - 큰 학습률로 시작하고 학습 속도가 느려질 때 학습률을 낮추면 최적으 고정학습률 보다 좋은 솔루션을 빨리 발견할 수 있음
 
## 규제를 사용해 과대적합 피하기
- L1, L2 규제
  - 신경망의 연결 가중치를 제한하기 위해 L2 규제를 사용 가능
  - 많은 가중치가 0인 희소 모델을 만들기 위해 L1 규제 사용 가능
- 드롭아웃
  - 매 훈련 스텝에서 각 뉴런은 임시적으로 드롭아웃돌 확률 p를 가짐
  - 하이퍼파라미터 p를 드롭아웃 비율이라고 함
  - 훈련이 끝난 후에는 드롭아웃을 적용하지 않음
  - 매 스텝에서 랜덤하게 드롭되기 때문에 특정 뉴런에게만 의존되는 상황을 피할 수 있음
  - 또 다른 이해방법으로는 매 스탭에서 고유의 네트워크가 생성된다고 생각할 수 있음 (앙상블과 유사)
- 맥스-노름 규제
  - ∣∣w∣∣₂ <=r
  - r을 줄이면 규제의 양이 증가하여 과대적합을 감소싴는데 도움이 됨
  - 불안정한 그레이디언트 문제를 완화하는데 도움을 줌
